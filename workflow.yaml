main:
  steps:
    - run-selenium-ingestor:
        call: googleapis.run.v1.namespaces.jobs.run
        args:
          name: projects/${sys.get_env("GCP_PROJECT_ID")}/locations/${sys.get_env("GCP_REGION")}/jobs/selenium-ingestor-job

    - create-dataproc-cluster:
        call: http.post
        args:
          url: https://dataproc.googleapis.com/v1/projects/${sys.get_env("GCP_PROJECT_ID")}/regions/${sys.get_env("GCP_REGION")}/clusters
          auth:
            type: OIDC
          body:
            projectId: ${sys.get_env("GCP_PROJECT_ID")}
            clusterName: ephemeral-cluster
            config:
              masterConfig:
                machineTypeUri: n1-standard-2
              workerConfig:
                numInstances: 2
                machineTypeUri: n1-standard-2
        result: cluster_operation

    - check-cluster-status:
        call: http.get
        args:
          url: https://dataproc.googleapis.com/v1/${cluster_operation.name}
          auth:
            type: OIDC
        result: cluster_status

    - check-if-cluster-done:
        switch:
          - condition: ${cluster_status.done == true}
            next: run-pyspark-job
          - condition: ${cluster_status.done == false}
            next: wait-before-cluster-check

    - wait-before-cluster-check:
        call: sys.sleep
        args:
          seconds: 10
        next: check-cluster-status

    - run-pyspark-job:
        call: http.post
        args:
          url: https://dataproc.googleapis.com/v1/projects/${sys.get_env("GCP_PROJECT_ID")}/regions/${sys.get_env("GCP_REGION")}/jobs:submit
          auth:
            type: OIDC
          body:
            projectId: ${sys.get_env("GCP_PROJECT_ID")}
            job:
              placement:
                clusterName: ephemeral-cluster
              pysparkJob:
                mainPythonFileUri: gs://infass/pyspark-jobs/build_merc_table.py
        result: pyspark_job

    - check-job-status:
        call: http.get
        args:
          url: https://dataproc.googleapis.com/v1/${pyspark_job.name}
          auth:
            type: OIDC
        result: job_status

    - check-if-job-done:
        switch:
          - condition: ${job_status.done == true}
            next: delete-dataproc-cluster
          - condition: ${job_status.done == false}
            next: wait-before-job-check

    - wait-before-job-check:
        call: sys.sleep
        args:
          seconds: 10
        next: check-job-status

    - delete-dataproc-cluster:
        call: http.delete
        args:
          url: https://dataproc.googleapis.com/v1/projects/${sys.get_env("GCP_PROJECT_ID")}/regions/${sys.get_env("GCP_REGION")}/clusters/ephemeral-cluster
          auth:
            type: OIDC
